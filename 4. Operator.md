# 4. Operator

### 목적 

Operator 는 다른 SW 실행 작업의 복잡성을 완화하는 목적으로 만들어진 SW 이다.  Operator는 사용자가 Application을 패키징, 배포 및 관리를 편리하게 할 수 있도록 한다. 본 프로젝트에서는 Operator를 통해 Elasticsearch 와 Cluster Logging Instance 를 설치하고 관리한다. 

- python 3.8.6 설치 필요 (pyyaml, jinja2 라이브러리 포함)
<br></br>

## Operator source 다운로드

**1. Operator Hub 비활성화**
- ocp4에서는 기본적으로 [Operator Hub](https://operatorhub.io/)와 연결되어 클러스터에 사용할 수 있는 operator를 검색 및 사용이 가능하도록 설정되어 있음
- disconnected 환경에서는 내부 저장소를 통해 operator를 사용하므로 기본적으로 설정되어 있는 Operator Hub를 비활성화

    ```bash
    oc patch OperatorHub cluster --type json \
    -p '[{"op": "add", "path": "/spec/disableAllDefaultSources", "value": true}]'
    ```

**2. 내부 저장소에 로그인**
- 내부 저장소 생성 시 만들어준 사용자로 registry에 로그인

    ```bash
    podman login -u devops -p dkagh1. 'private registry address -ex) https://bastion.redhat2.cccr.local:5000'
    ```

**3. 실제 mirror 할 operator 목록 작성**
- operator 설치 시 사용할 작업 디렉토리를 생성
- 작업 디렉토리 : ~/operator 
- 카탈로그 안의 모든 operator 를 mirror 하지 않고 필요한 operator 만을 mirror 할 것이므로 사용할 operator를 정의

    ```bash
    mkdir operator && cd operator 

    vi offline-operator-list
    # 다운 받아 올 operator list 작성 
    cluster-logging
    elasticsearch-operator
    ```

**4. 특정 operator만 mirror하는 python 스크립트 실행**
- python 스크립트로 진행
- 사용할 버전에 맞게 --operator-channel 옵션 설정
- [mirror-operator-catalogue.py](https://github.com/cccr2guro-redhat/Disconnected-Openshift4/blob/master/mirror-operator-catalogue.py) 참고 

    ```bash
    vi mirror-operator-catalogue.py
    ...
    parser.add_argument(
        "--operator-channel",
        default="4.4",
        help="Operator Channel. Default 4.4")

    ...

    python mirror-operator-catalogue.py --catalog-version 1.0.0 \
    --authfile /opt/registry/pull-secret --registry-olm bastion.redhat2.cccr.local:5000 \
    --registry-catalog bastion.redhat2.cccr.local:5000 --operator-file ./offline-operator-list --icsp-scope=namespace
    ```

**5. image content 소스 정책 정의**
- 현재 작업 디렉토리에 /openshift-disconnected-operators/ publish라는 디렉토리가 생성됨
- 하위의  olm-icsp.yaml 과 rh-catalog-source.yaml 실행

    ```bash
    cd ~/operator/openshift-disconnected-operators/publish

    oc create -f olm-icsp.yaml
    oc create -f rh-catalog-source.yaml
    ```

**6. 생성된 pod 및 catalogsource 확인**
- catalogsource와 packagemanifest 확인 
- namespace는 openshift-marketplace 로 설정됨

    ```bash
    oc get pods -n openshift-marketplace
    NAME                                    READY   STATUS    RESTARTS   AGE
    marketplace-operator-5bc576bff4-vr7cr   1/1     Running   0          4h8m
    redhat-operators-s7ks7                  1/1     Running   0          5d1h

    oc get catalogsource -n openshift-marketplace
    NAME               DISPLAY           TYPE   PUBLISHER   AGE
    redhat-operators   Red Hat Catalog   grpc   Red-Hat     16d

    oc get packagemanifest -n openshift-marketplace
    NAME                     CATALOG           AGE
    elasticsearch-operator   Red Hat Catalog   16d
    cluster-logging          Red Hat Catalog   16d
    ```
<br></br>

## Elasticsearch Operators 설치

**1. 작업 디렉토리 생성**
- 작업 디렉토리 : ~/cluster-logging

    ```bash
    mkdir ~/cluster-logging && cd ~/cluster-logging 
    ```

**2. Elasticsearch Operator의 네임스페이스 작성**
- Elasticsearch namespace : openshift-operators-redhat

    ```bash
    vi ~/cluster-logging/es-namespace.yaml 
    # Example of elasticsearch namespace 
    apiVersion: v1
    kind: Namespace
    metadata:
      name: openshift-operators-redhat
      annotations:
        openshift.io/node-selector: ""
      labels:
        openshift.io/cluster-logging: "true"
        openshift.io/cluster-monitoring: "true"
    ```

- 생성
    ```bash
    oc create -f  ~/cluster-logging/es-namespace.yaml 
    ```

**3. Elasticsearch Operator의 Operator Group 생성**
- Operator Group : openshift-operators-redhat
    ```bash
    vi ~/cluster-logging/es-og.yaml
    # Example of Operator Group 
    apiVersion: operators.coreos.com/v1
    kind: OperatorGroup
    metadata:
      name: openshift-operators-redhat
      namespace: openshift-operators-redhat
    spec: {}
    ```

- 생성

    ```bash
    oc create -f ~/cluster-logging/es-og.yaml
    ```

**4. Elasticsearch Operator Subscription 생성**
- 사용 가능한 채널을 검색해보고, 사용 가능한 채널에 맞춰 Subscription을 생성

    ```bash
    oc get packagemanifest elasticsearch-operator -n openshift-marketplace

    vi ~/cluster-logging/es-sub.yaml
    # Example of subscription 
    apiVersion: operators.coreos.com/v1alpha1
    kind: Subscription
    metadata:
      name: elasticsearch-operator
      namespace: openshift-operators-redhat
    spec:
      channel: "4.4"
      installPlanApproval: "Automatic"
      name: elasticsearch-operator
      source: redhat-operators
      sourceNamespace: openshift-marketplace
    ```

- 생성

    ```bash
    oc create -f ~/cluster-logging/es-sub.yaml
    ```

**5. CSV 생성 확인** 
- CSV = Cluster Service Versions
- Elasticsearch Operator 와 관련된 모든 namespace에 CSV가 생성되었는지 확인

    ```bash
    oc get csv --all-namespaces
    ```

**6. RBAC 생성**
- RBAC = role-based access control ( 역할 기반 접근 제어 )
- Prometheus에게 권한을 부여하기 위해 RBAC를 작성하고 생성

    ```bash
    vi ~/cluster-logging/es-rbac.yaml
    # Example of RBAC
    apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      name: prometheus-k8s
      namespace: openshift-operators-redhat
    rules:
    - apiGroups:
      - ""
      resources:
      - services
      - endpoints
      - pods
      verbs:
      - get
      - list
      - watch
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
      name: prometheus-k8s
      namespace: openshift-operators-redhat
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: Role
      name: prometheus-k8s
    subjects:
    - kind: ServiceAccount
      name: prometheus-k8s
      namespace: openshift-operators-redhat
    ```

- 생성

    ```bash
    oc create -f ~/cluster-logging/es-rbac.yaml
    ```

**7. Elasticsearch Operator 생성 확인**
- Elasticsearch Operator의 namespace를 통해 elasticsearch-operator 확인 
    ```bash
    oc get pod -n openshift-operators-redhat -o wide
    NAME                                      READY   STATUS    RESTARTS   AGE    IP          NODE                           NOMINATED NODE   READINESS GATES
    elasticsearch-operator-6cb58494cb-sgqb7   1/1     Running   0          5d1h   10.1.4.15   service-2.redhat2.cccr.local   <none>           <none>

    # log 확인 
    oc logs elasticsearch-operator-6cb58494cb-sgqb7 -n openshift-operators-redhat
    oc describe pod/elasticsearch-operator-6cb58494cb-sgqb7 -n openshift-operators-redhat
    ```
<br></br>
## Cluster Logging Operators 설치

**1. Cluster Logging Operator의 namespace 작성**
- Cluster Logging operator namespace : openshift-logging
    ```bash
    vi ~/cluster-logging/clo-namespace.yaml

    apiVersion: v1
    kind: Namespace
    metadata:
      name: openshift-logging
      annotations:
        openshift.io/node-selector: ""
      labels:
        openshift.io/cluster-logging: "true"
        openshift.io/cluster-monitoring: "true"
    ```

- 생성

    ```bash
    oc create -f ~/cluster-logging/clo-namespace.yaml
    ```

**2. Cluster Logging Operator의 Operator Group 생성**
- Operator Group : cluster-logging
    ```bash
    vi ~/cluster-logging/clo-og.yaml

    apiVersion: operators.coreos.com/v1
    kind: OperatorGroup
    metadata:
      name: cluster-logging
      namespace: openshift-logging
    spec:
      targetNamespaces:
      - openshift-logging
    ```

- 생성

    ```bash
    oc create -f ~/cluster-logging/clo-sub.yaml
    ```

**3. cluster-logging Subscription 생성**
- 사용 가능한 채널을 검색해보고, 사용 가능한 채널에 맞춰 Subscription을 생성

    ```bash
    vi ~/cluster-logging/clo-sub.yaml

    apiVersion: operators.coreos.com/v1alpha1
    kind: Subscription
    metadata:
      name: cluster-logging
      namespace: openshift-logging
    spec:
      channel: "4.4"
      name: cluster-logging
      source: redhat-operators
      sourceNamespace: openshift-marketplace
    ```

- 생성

    ```bash
    oc create -f ~/cluster-logging/clo-sub.yaml
    ```

**4. CSV 생성 확인**
- Cluster Logging과 Elasticsearch Operator가 모두 나오는지 확인 

    ```bash
    oc get clusterserviceversions.operators.coreos.com -n openshift-logging

    NAME                                           DISPLAY                  VERSION                 REPLACES   PHASE
    clusterlogging.4.4.0-202009161309.p0           Cluster Logging          4.4.0-202009161309.p0              Succeeded
    elasticsearch-operator.4.4.0-202009161309.p0   Elasticsearch Operator   4.4.0-202009161309.p0              Succeeded
    ```
<br></br>
## Cluster Logging Instance 설치

**1. Cluster Logging Operator Instance 생성**
- Cluster Logging 노드의 수와 Memory, Storage를 유의하여 설정
- nodeSelecor.node-role.kubernetes.io/_____: '' 로 node-selector를 설정하여 원하는 노드에 인스턴스 생성 가능 

    ```bash
    vi ~/cluster-logging/clo-instance.yaml
    # Example of logging operator instance 
    apiVersion: "logging.openshift.io/v1"
    kind: "ClusterLogging"
    metadata:
      name: "instance"
      namespace: "openshift-logging"
    spec:
      managementState: "Managed"
      logStore:
        type: elasticsearch
        elasticsearch:
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
          nodeCount: 1
          nodeSelector:
              node-role.kubernetes.io/infra: ''
          redundancyPolicy: ZeroRedundancy
          storage:
            storageClassName: standard
            size: 10Gi
      visualization:
        type: "kibana"
        kibana:
          replicas: 1
          nodeSelector:
            node-role.kubernetes.io/infra: ''
      curation:
        type: "curator"
        curator:
          schedule: "30 3 * * *"
          nodeSelector:
            node-role.kubernetes.io/infra: ''
      collection:
        logs:
          type: "fluentd"
          fluentd: {}
    ```

- 생성

    ```bash
    oc create -f ~/cluster-logging/clo-instance.yaml
    ```

**2. PV 생성**
- instance 생성 시, 자동으로 PVC가 생성됨
- 생성된 PVC에 연결할 수 있도록 PV 생성.
- PV 정의시 spec.claimRef.name 에 생성된 PVC의 이름 기입

    ```bash
    oc get pvc

    NAME                                         STATUS   VOLUME                  CAPACITY   ACCESS MODES   STORAGECLASS   AGE
    elasticsearch-elasticsearch-cdm-n0ll23ai-1   Bound    elasticsearch-cdm-pv1   10Gi       RWO            standard       3d23h

    vi elasticsearch-pv-1.yaml
    # Example of pv 
    apiVersion: v1
    kind : PersistentVolume
    metadata:
      name : elasticsearch-cdm-pv1
    spec:
      capacity:
        storage: 10Gi
      accessModes:
      - ReadWriteOnce
      nfs:
        path: /pv/logging
        server: 10.10.10.17
      PersistentVolumeReclaimPolicy: Retain
      storageClassName: standard
      claimRef:
        name: elasticsearch-elasticsearch-cdm-n0ll23ai-1
        namespace: openshift-logging
    ```

**3. 생성된 Pods 확인** 
- Operator, Elasticsearch, Kibana, Fluentd pod 가 생성되는 것 확인

    ```bash
    oc get pod -n openshift-logging -o wide
    ```

**4. Kibana에서 로그 확인 및 Dashboard 접속**
- kibana dash board url : kibana-openshift-logging.apps.redhat2.cccr.local
    ```bash
    oc get route -n openshift-logging

    NAME     HOST/PORT                                                  PATH   SERVICES   PORT    TERMINATION          WILDCARD
    kibana   kibana-openshift-logging.apps.redhat2.cccr.local          kibana     <all>   reencrypt/Redirect   None
    ```

- url로 접속하여 Dashboard가 정상적으로 나오는지 확인 
<img src="/image/KibanaDB.png" width="500" height="300">


<br></br>

---
### 참고문헌
https://docs.openshift.com/container-platform/4.4/operators/olm-what-operators-are.html
https://docs.openshift.com/container-platform/4.4/operators/olm-restricted-networks.html